# TrendWatcher â€” SDG Lab MVP

Internal signal intelligence tool that analyzes Reddit discussions daily to identify emerging topics, growing trends, user pain points, and actionable product hypotheses for SDG Lab.

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            Frontend (SPA)                 â”‚
â”‚   React 19 + TS + Vite + Tailwind        â”‚
â”‚   Feature Sliced Design (FSD)            â”‚
â”‚   useAutoReport hook (client-side cron)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚       Supabase           â”‚
    â”‚  Edge Function           â”‚ â† daily-report cron job
    â”‚  (fetch â†’ analyze â†’ email)â”‚
    â”‚  PostgreSQL              â”‚ â† Report storage (Phase 2)
    â”‚  pg_cron                 â”‚ â† Schedule trigger
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Reddit API  â”‚ OpenAI   â”‚ Resend (email)
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### FSD Structure

```
src/
â”œâ”€â”€ app/              # App shell: providers, routing, global styles
â”œâ”€â”€ pages/            # Route-level components (Dashboard, Settings)
â”œâ”€â”€ widgets/          # Composite UI blocks (TrendBoard, SignalList, ReportCard)
â”œâ”€â”€ features/         # User actions (GenerateReport, ConfigureSubreddits, FilterSignals)
â”œâ”€â”€ entities/         # Domain objects (Report, Signal, Subreddit)
â”œâ”€â”€ shared/           # Infrastructure: UI kit, API clients, types, utils
â”‚   â”œâ”€â”€ api/          # AI service, Reddit service, report storage
â”‚   â”œâ”€â”€ ui/           # Reusable components (Button, Card, Badge, Skeleton)
â”‚   â”œâ”€â”€ lib/          # Types, Zustand store, utilities
â”‚   â””â”€â”€ config/       # App & API configuration
â””â”€â”€ test/             # Test setup
```

### Data Flow

1. **Fetch** â€” Reddit service fetches hot/new posts from configured subreddits (last 48h)
2. **Analyze** â€” AI service processes posts through OpenAI (gpt-4o-mini) with a structured analysis prompt
3. **Structure** â€” Response is parsed into typed signals: emerging topics, growing trends, pain points, product hypotheses
4. **Display** â€” Dashboard renders the report with filterable signal cards
5. **Persist** â€” Reports stored in IndexedDB (MVP) with abstraction layer for future Supabase migration
6. **Email** â€” Report sent to configured recipients via Resend

### Daily Cron Job

The system supports two scheduling modes:

**Client-side (MVP):** `useAutoReport` hook runs in the browser while the dashboard is open. Checks every 60 seconds if the configured hour has passed and no report exists for today. If triggered, it generates a report and sends email automatically.

**Server-side (Production):** Supabase Edge Function `daily-report` at `supabase/functions/daily-report/index.ts`. Triggered by pg_cron â€” no browser needed. Full pipeline: Reddit fetch â†’ OpenAI analysis â†’ DB storage â†’ Resend email.

```sql
-- pg_cron setup (Supabase SQL Editor)
select cron.schedule(
  'daily-trendwatcher-report',
  '0 9 * * *',  -- every day at 09:00 UTC
  $$
  select net.http_post(
    url := 'https://<project-ref>.supabase.co/functions/v1/daily-report',
    headers := jsonb_build_object(
      'Authorization', 'Bearer ' || current_setting('supabase.service_role_key')
    ),
    body := '{}'::jsonb
  );
  $$
);
```

### AI Analysis Approach

**LLM-based analysis** (not embeddings/clustering) was chosen for MVP because:

- **Understands nuance** â€” sarcasm, tone, subtext that embeddings miss
- **Generates hypotheses** â€” can reason about *why* and *what to build*, not just find patterns
- **Handles daily volume well** â€” 2-3 subreddits produce hundreds of posts/day, fitting within context windows
- **Structured JSON output** â€” parseable, directly renderable results
- **Faster to ship** â€” no vector DB, no embedding pipeline, no cluster tuning

### Scaling Beyond MVP: Embeddings & Clustering

For longer-term, quantitative analysis the system can be extended with:

**Embeddings** (vector representations of post meaning):
- Cross-day topic tracking: compare today's posts against yesterday's semantically, not by keywords
- Duplicate detection: group "lonely in new city" / "moved, no friends" / "isolated after relocation" as one theme
- Anomaly detection: mathematically measure when a topic cluster grows 10x in 24h

**Clustering** (HDBSCAN / k-means on embeddings):
- Long-term trend visualization: 30-day topic evolution charts
- New topic discovery: posts that don't fit existing clusters = emerging signals
- Topic landscape maps: 2D scatter plots (via UMAP) showing what communities discuss

**Why not for MVP:** LLM gives 80% of value with 20% of effort. Embeddings + clustering add quantitative precision and historical comparison but require vector DB infrastructure (Pinecone / pgvector), embedding pipeline, and cluster tuning â€” justified after product-market fit.

## Tech Stack

| Concern | Choice |
|---|---|
| Framework | React 19 + TypeScript |
| Build | Vite 7 |
| Architecture | Feature Sliced Design with path aliases |
| Styling | Tailwind CSS v4 |
| State | Zustand (persisted settings) |
| Data fetching | React Query |
| Forms | React Hook Form + Zod |
| AI | OpenAI gpt-4o-mini (mock mode by default) |
| Storage | IndexedDB via `idb` (MVP) â†’ Supabase PostgreSQL (prod) |
| Backend | Supabase Edge Functions (planned) |
| Email | Resend (planned) |
| Linting | Biome |
| Testing | Vitest |
| Icons | Lucide React |

## Quick Start

```bash
# Prerequisites
node >= 22 (use nvm)
nvm use

# Install
npm install

# Start dev server
npm run dev        # â†’ http://localhost:3000

# Build
npm run build

# Test
npm run test       # watch mode
npm run test:run   # single run

# Lint
npm run lint
npm run lint:fix
```

## Configuration

Copy `.env.example` to `.env`:

```bash
# AI Provider: "mock" (default) or "openai"
VITE_AI_SERVICE_TYPE=mock

# Required when VITE_AI_SERVICE_TYPE=openai
VITE_OPENAI_API_KEY=sk-...

# For email delivery (planned)
VITE_RESEND_API_KEY=
```

**Mock mode** works out of the box â€” generates realistic sample reports with pre-built signals. Switch to `openai` with a valid API key for real Reddit analysis.

## Report Format

Each report contains structured signals across 4 categories:

| Category | What it captures |
|---|---|
| ğŸ†• **Emerging Topics** | New themes appearing for the first time |
| ğŸ“ˆ **Growing Trends** | Topics accelerating vs. baseline (with % growth) |
| ğŸ˜° **Pain Points** | User frustrations mapped to product domains |
| ğŸ’¡ **Product Hypotheses** | Actionable ideas derived from signals |

Each signal includes: strength (high/medium/low), sentiment, post count, source subreddits, and growth percentage where applicable.

## Key Design Decisions

**Provider-agnostic AI**: `AIAnalysisService` interface abstracts OpenAI â€” swap to Anthropic, local LLM, or any provider by implementing one interface.

**Storage abstraction**: `ReportStorage` interface decouples persistence â€” IndexedDB for MVP, Supabase for production, with zero changes to business logic.

**Storybook-ready UI**: All shared/ui components are self-contained with typed props â€” ready for extraction into a design system package.

**No backend dependency for MVP**: Mock services enable full development and demo without Reddit API access or OpenAI keys.

## Answers to Mandatory Questions

### Which signals are most valuable for SDG Lab?

1. **Unmet needs with emotional urgency** â€” when users express pain with strong emotion around companionship, emotional support, or communication. Direct product opportunity signals.
2. **Behavioral shifts in coping mechanisms** â€” when users collectively adopt new patterns (AI chatbots for loneliness, Discord support groups). Shows organic market movement.
3. **Negative sentiment toward existing solutions** â€” frustration with therapy apps, dating apps, social media. Reveals gaps for differentiated positioning.

### How to make this a competitive advantage?

- **Speed**: Daily signals vs. quarterly reports. Launch MVPs in weeks while competitors are in research.
- **Domain tuning**: Prompts, subreddit selection, signal taxonomy tuned to SDG Lab's verticals.
- **Historical memory**: Longitudinal dataset of pain point evolution becomes a moat over time.
- **Hypothesis-to-backlog pipeline**: Every output is actionable, not just informational.

### How to automate trend-to-MVP pipeline?

1. **Phase 1** (now): Structured reports â†’ human prioritization
2. **Phase 2**: Scoring system `opportunity = strength Ã— domain_fit Ã— competition_gap Ã— urgency` â†’ auto-ranked hypotheses in Slack
3. **Phase 3**: AI-generated product specs (personas, user stories, MVP scope) from approved hypotheses
4. **Phase 4**: Full loop: detect signal â†’ score â†’ generate spec â†’ create repo from template â†’ assign team. Human approval at gates only.

## License

Internal tool â€” SDG Lab proprietary.
